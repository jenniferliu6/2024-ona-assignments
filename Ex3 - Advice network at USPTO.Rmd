---
title: "Ex3 - Advice network at USPTO"
author: "Jennifer Liu"
date: "2024-04-02"
output: html_document
---

## Part 1: Load data

Load the following data: + applications from `app_data_sample.parquet` + edges from `edges_sample.csv`

```{r}
library(arrow)
library(dplyr)
library(readr)

data_path <- "C:\\Users\\Admin\\Downloads\\"

# Reading a Parquet file
applications <- read_parquet(paste0(data_path, "app_data_sample.parquet"))

# Reading a CSV file and suppressing the column type message
edges <- read_csv(paste0(data_path, "edges_sample.csv"), show_col_types = FALSE)
```

```{r}
library(dplyr)
#install.packages("gender")
library(gender)
examiner_names <- applications %>% distinct(examiner_name_first)

head(examiner_names)
```

## Get gender for examiners

We'll get gender based on the first name of the examiner, which is recorded in the field `examiner_name_first`. We'll use library `gender` for that, relying on a modified version of their own [example](https://cran.r-project.org/web/packages/gender/vignettes/predicting-gender.html).

Note that there are over 2 million records in the applications table -- that's because there are many records for each examiner, as many as the number of applications that examiner worked on during this time frame. Our first step therefore is to get all *unique* names in a separate list `examiner_names`. We will then guess gender for each one and will join this table back to the original dataset. So, let's get names without repetition:

Now let's use function `gender()` as shown in the example for the package to attach a gender and probability to each name and put the results into the table `examiner_names_gender`. Note that the first time you run this code, you need to say "Yes" in the console to download the gender data.

```{r}
# install.packages("tidyr")
library(tidyr)

examiner_names_gender <- examiner_names %>% do(results = gender(.$examiner_name_first, method = 'ssa')) %>% unnest(cols = c(results), keep_empty = TRUE) %>% select(
  examiner_name_first = name, 
  gender,
  proportion_female
)

head(examiner_names_gender)
```

Finally, let's join that table back to our original applications data and discard the temporary tables we have just created to reduce clutter in our environment.

```{r gender-3}
# remove extra columns from the gender table
examiner_names_gender <- examiner_names_gender %>% 
  select(examiner_name_first, gender)

# joining gender back to the dataset
applications <- applications %>% 
  left_join(examiner_names_gender, by = "examiner_name_first")

# cleaning up
rm(examiner_names)
rm(examiner_names_gender)
gc()

```

## Guess the examiner's race

We'll now use package `wru` to estimate likely race of an examiner. Just like with gender, we'll get a list of unique names first, only now we are using surnames.

```{r race-1}
#install.packages("wru")
library(wru)

examiner_surnames <- applications %>% 
  select(surname = examiner_name_last) %>% 
  distinct()

examiner_surnames
```

We'll follow the instructions for the package outlined here <https://github.com/kosukeimai/wru>.

```{r race-2}
examiner_race <- predict_race(voter.file = examiner_surnames, surname.only = T) %>% 
  as_tibble()

examiner_race
```

As you can see, we get probabilities across five broad US Census categories: white, black, Hispanic, Asian and other. (Some of you may correctly point out that Hispanic is not a race category in the US Census, but these are the limitations of this package.)

Our final step here is to pick the race category that has the highest probability for each last name and then join the table back to the main applications table. See this example for comparing values across columns: <https://www.tidyverse.org/blog/2020/04/dplyr-1-0-0-rowwise/>. And this one for `case_when()` function: <https://dplyr.tidyverse.org/reference/case_when.html>.

```{r race-3}
examiner_race <- examiner_race %>% 
  mutate(max_race_p = pmax(pred.asi, pred.bla, pred.his, pred.oth, pred.whi)) %>% 
  mutate(race = case_when(
    max_race_p == pred.asi ~ "Asian",
    max_race_p == pred.bla ~ "black",
    max_race_p == pred.his ~ "Hispanic",
    max_race_p == pred.oth ~ "other",
    max_race_p == pred.whi ~ "white",
    TRUE ~ NA_character_
  ))

examiner_race
```

Let's join the data back to the applications table.

```{r race-4}
# removing extra columns
examiner_race <- examiner_race %>% 
  select(surname,race)

applications <- applications %>% 
  left_join(examiner_race, by = c("examiner_name_last" = "surname"))

rm(examiner_race)
rm(examiner_surnames)
gc()
```

## Examiner's tenure

To figure out the timespan for which we observe each examiner in the applications data, let's find the first and the last observed date for each examiner. We'll first get examiner IDs and application dates in a separate table, for ease of manipulation. We'll keep examiner ID (the field `examiner_id`), and earliest and latest dates for each application (`filing_date` and `appl_status_date` respectively). We'll use functions in package `lubridate` to work with date and time values.

```{r tenure-1}
#install.packages("lubridate")
library(lubridate) # to work with dates

examiner_dates <- applications %>%
  select(examiner_id, filing_date, appl_status_date)

examiner_dates
```

The dates look inconsistent in terms of formatting. Let's make them consistent. We'll create new variables `start_date` and `end_date`.

```{r tenure-2}
examiner_dates <- examiner_dates %>% 
  mutate(start_date = ymd(filing_date), end_date = as_date(dmy_hms(appl_status_date)))
```

```{r}
head(examiner_dates)
```

Let's now identify the earliest and the latest date for each examiner and calculate the difference in days, which is their tenure in the organization.

```{r tenure-3}
examiner_dates <- examiner_dates %>% 
  group_by(examiner_id) %>% 
  summarise(
    earliest_date = min(start_date, na.rm = TRUE), 
    latest_date = max(end_date, na.rm = TRUE),
    tenure_days = interval(earliest_date, latest_date) %/% days(1)
    ) %>% 
  filter(year(latest_date)<2018)

examiner_dates
```

Joining back to the applications data.

```{r tenure-4}
applications <- applications %>% 
  left_join(examiner_dates, by = "examiner_id")

rm(examiner_dates)
gc()
```

## In order to keep these steps saved, I will save the file and reload the data back into R.

```{r}
write.csv(applications, "applications_updated.csv")

applications_updated = read.csv("applications_updated.csv")
```

## Part 2:

Pick two workgroups you want to focus on (remember that a workgroup is represented by the first 3 digits of `examiner_art_unit` value)

How do they compare on examinersâ€™ demographics? Show summary statistics and plots.

```{r}
#Identify workgroups
attach(applications_updated)
applications_updated$workgroup = substr(applications_updated$examiner_art_unit, 1, 3)
```

```{r}
selected_workgroups = applications_updated %>% filter(workgroup %in% c("176", "213"))

head(selected_workgroups)
```

```{r}
if("workgroup" %in% colnames(selected_workgroups)) {
  grouped_data <- selected_workgroups %>%
    group_by(workgroup) %>%
    summarize(count = n()) # Example of counting the number of rows in each group

  print(grouped_data)
} else {
  print("Column 'workgroup' not found in 'selected_workgroups'")
}
```

```{r}
demographic <- selected_workgroups %>%
  group_by(workgroup) %>%
  summarize(
    count = n(),
    proportion_white = mean(selected_workgroups$race.x=="white", na.rm = TRUE),
    proportion_female = mean(gender=="female", na.rm = TRUE),    
    avg_tenure = mean(tenure_days, na.rm = TRUE)           
  )

print(demographic)
```

```{r}
proportion_male = selected_workgroups %>% group_by(workgroup) %>% summarise(proportion_male = mean(gender == 'male', na.rm = TRUE)) %>% ungroup()
```

```{r}
#install.packages("ggplot2")
library(ggplot2)
ggplot(proportion_male, aes(x=workgroup, y=proportion_male, fill=workgroup)) + geom_bar(stat = "identity", width=1) + scale_fill_manual(values=c("darkgreen","orange")) + labs(title = "Male Proportion For Selected Workgroup", x="workgroup",y="male proportion") + theme_minimal()
```

From the chart, workgroup 213 has a higher proportion of male members compared to workgroup 176, as evidenced by the height of the orange bar (for workgroup 213) relative to the green bar (for workgroup 176). There is a notable difference as shown in the visual comparison above.

```{ggplot(selected_workgroups, aes(x = tenure_days, fill = workgroup)) + geom_histogram(position = "dodge", binwidth = 500) + labs(title = "Tenure (in Days) Distribution Breakdown by workgroups", x="Tenure (in days)", y = "Frequency") + scale_fill_manual(values = c("176" = "darkgreen", "213" = "orange"))}
```

## Part 3

Create advice networks from `edges_sample` and calculate centrality scores for examiners in your selected workgroups

```{r}
filter_edges = edges %>% filter(application_number %in% applications_updated$application_number)

library(igraph)
degree_centrality = degree(network)
between_centrality = betweenness(network)
close_centrality = closeness(network)

applications_updated$degree_centrality <- degree_centrality[match(applications_updated$examiner_id, V(network)$name)]

applications_updated$between_centrality <- between_centrality[match(applications_updated$examiner_id, V(network)$name)]

applications_updated$close_centrality <- close_centrality[match(applications_updated$examiner_id, V(network)$name)]
```

Recall that we select workgroups "176", "213"

```{r}
library(dplyr)
library(igraph)
library(ggraph)

# Filter the applications for selected workgroups
selected_examiners = applications_updated %>% filter(workgroup %in% c("176", "213"))

# Calculate degree centrality
V(network)$degree_centrality = degree(network)

# Create a Race data frame with unique examiner_id and race.x values
Race = applications_updated %>% 
  select(examiner_id, race) %>% 
  distinct()

# Convert examiner_id to character to ensure matching
Race$examiner_id = as.character(Race$examiner_id)

# Assign race to each vertex in the network
for (i in seq_along(V(network))) {
  vertex_name <- V(network)$name[i]
  V(network)$race[i] <- Race$race[Race$examiner_id == vertex_name]
}

# Visualize the network
ggraph(network, layout = "tree") + 
  geom_edge_link(color = "darkgreen") + 
  geom_node_point(aes(size = degree_centrality, color = race)) + 
  scale_color_manual(values = c("Category1" = "red", "Category2" = "blue", "Category3" = "green")) +
  theme_minimal() +
  labs(title = "Network Graph of Degree Centrality and Race")


```
